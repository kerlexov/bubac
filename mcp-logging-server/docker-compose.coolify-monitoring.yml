version: '3.8'

services:
  # Main MCP Logging Server
  mcp-logging-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp-logging-server
    restart: unless-stopped
    environment:
      # Database configuration
      - MCP_LOGGING_DB_CONNECTION=/app/data/logs.db
      - MCP_LOGGING_CONFIG_PATH=/app/config/config.yaml
      - MCP_LOGGING_RECOVERY_DIR=/app/recovery

      # Authentication settings
      - API_KEY_REQUIRED=${API_KEY_REQUIRED:-true}
      - API_KEYS_CONFIG_PATH=/app/config/api-keys.yaml

      # Rate limiting
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-true}
      - RATE_LIMIT_REQUESTS_PER_MINUTE=${RATE_LIMIT_REQUESTS_PER_MINUTE:-1000}
      - RATE_LIMIT_BURST=${RATE_LIMIT_BURST:-100}

      # Security settings
      - TLS_ENABLED=false  # TLS handled by Coolify's reverse proxy
      - HTTPS_REDIRECT=false  # Handled by Coolify
      - SECURITY_HEADERS_ENABLED=${SECURITY_HEADERS_ENABLED:-true}
      - CORS_ENABLED=${CORS_ENABLED:-false}
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS:-}

      # Data protection
      - MASK_SENSITIVE_FIELDS=${MASK_SENSITIVE_FIELDS:-true}
      - SENSITIVE_FIELDS=${SENSITIVE_FIELDS:-password,token,secret,key,authorization,credit_card,ssn,api_key}

      # Audit settings
      - AUDIT_ENABLED=${AUDIT_ENABLED:-true}
      - AUDIT_LOG_LEVEL=${AUDIT_LOG_LEVEL:-INFO}
      - AUDIT_RETENTION_DAYS=${AUDIT_RETENTION_DAYS:-90}

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}

      # Monitoring
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
      - HEALTH_CHECK_ENABLED=${HEALTH_CHECK_ENABLED:-true}
      - HEALTH_CHECK_INTERVAL=${HEALTH_CHECK_INTERVAL:-30s}

      # Performance tuning
      - BUFFER_SIZE=${BUFFER_SIZE:-10000}
      - BUFFER_FLUSH_TIMEOUT=${BUFFER_FLUSH_TIMEOUT:-5s}
      - BUFFER_MAX_BATCH_SIZE=${BUFFER_MAX_BATCH_SIZE:-100}
      - GO_MAX_PROCS=${GO_MAX_PROCS:-4}
      - GOMAXPROCS=${GOMAXPROCS:-4}
      - GOGC=${GOGC:-100}

      # Database optimization
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_CONNECTION_TIMEOUT=${DB_CONNECTION_TIMEOUT:-30s}
      - DB_QUERY_TIMEOUT=${DB_QUERY_TIMEOUT:-10s}

    volumes:
      - mcp_logging_data:/app/data
      - mcp_logging_config:/app/config
      - mcp_logging_recovery:/app/recovery
      - mcp_logging_audit:/app/audit

    ports:
      - "${INGESTION_PORT:-9080}:9080"  # Log ingestion API
      - "${MCP_PORT:-8081}:8081"        # MCP server

    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    networks:
      - mcp-logging-network

    security_opt:
      - no-new-privileges:true

    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m

    deploy:
      resources:
        limits:
          memory: ${MEMORY_LIMIT:-1Gi}
          cpus: '${CPU_LIMIT:-1.0}'
        reservations:
          memory: ${MEMORY_RESERVATION:-512Mi}
          cpus: '${CPU_RESERVATION:-0.5}'

    labels:
      # Coolify labels for automatic configuration
      - "coolify.managed=true"
      - "coolify.version=4.0"
      - "coolify.type=application"

      # Traefik labels for routing (Coolify uses Traefik)
      - "traefik.enable=true"

      # Log ingestion API routing
      - "traefik.http.routers.mcp-logging-api.rule=Host(`${API_DOMAIN}`) && (PathPrefix(`/v1/`) || PathPrefix(`/health`) || PathPrefix(`/metrics`))"
      - "traefik.http.routers.mcp-logging-api.entrypoints=websecure"
      - "traefik.http.routers.mcp-logging-api.tls.certresolver=letsencrypt"
      - "traefik.http.routers.mcp-logging-api.service=mcp-logging-api"
      - "traefik.http.services.mcp-logging-api.loadbalancer.server.port=9080"

      # MCP server routing
      - "traefik.http.routers.mcp-logging-mcp.rule=Host(`${MCP_DOMAIN}`) && PathPrefix(`/mcp`)"
      - "traefik.http.routers.mcp-logging-mcp.entrypoints=websecure"
      - "traefik.http.routers.mcp-logging-mcp.tls.certresolver=letsencrypt"
      - "traefik.http.routers.mcp-logging-mcp.service=mcp-logging-mcp"
      - "traefik.http.services.mcp-logging-mcp.loadbalancer.server.port=8081"

      # Security headers middleware
      - "traefik.http.middlewares.mcp-security-headers.headers.customrequestheaders.X-Forwarded-Proto=https"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.X-Content-Type-Options=nosniff"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.X-Frame-Options=DENY"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.X-XSS-Protection=1; mode=block"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.X-Content-Type-Options=nosniff"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.Strict-Transport-Security=max-age=31536000; includeSubDomains"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.Content-Security-Policy=default-src 'self'"
      - "traefik.http.middlewares.mcp-security-headers.headers.customresponseheaders.Referrer-Policy=strict-origin-when-cross-origin"

      # Apply security headers to both routers
      - "traefik.http.routers.mcp-logging-api.middlewares=mcp-security-headers"
      - "traefik.http.routers.mcp-logging-mcp.middlewares=mcp-security-headers"

      # Rate limiting middleware (optional, can be handled by application)
      - "traefik.http.middlewares.mcp-rate-limit.ratelimit.average=100"
      - "traefik.http.middlewares.mcp-rate-limit.ratelimit.burst=200"

      # Health check configuration
      - "coolify.healthcheck.enabled=true"
      - "coolify.healthcheck.path=/health"
      - "coolify.healthcheck.port=9080"
      - "coolify.healthcheck.interval=30s"
      - "coolify.healthcheck.timeout=10s"
      - "coolify.healthcheck.retries=3"

  # Loki for log aggregation
  loki:
    image: grafana/loki:2.9.0
    container_name: mcp-loki
    restart: unless-stopped
    volumes:
      - loki_data:/loki
      - ./monitoring/loki-config.yaml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    networks:
      - mcp-logging-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Promtail for log shipping to Loki
  promtail:
    image: grafana/promtail:2.9.0
    container_name: mcp-promtail
    restart: unless-stopped
    volumes:
      - ./monitoring/promtail-config.yaml:/etc/promtail/config.yaml
      - mcp_logging_data:/var/log/mcp:ro
      - /var/log/docker:/var/log/docker:ro
    command: -config.file=/etc/promtail/config.yaml
    networks:
      - mcp-logging-network
    depends_on:
      - loki

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: mcp-prometheus
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - mcp-logging-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for visualization
  grafana:
    image: grafana/grafana:10.1.0
    container_name: mcp-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "3000:3000"
    networks:
      - mcp-logging-network
    depends_on:
      - prometheus
      - loki
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Alertmanager for alerting
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: mcp-alertmanager
    restart: unless-stopped
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/config.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    networks:
      - mcp-logging-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: mcp-node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    networks:
      - mcp-logging-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  mcp-logging-network:
    driver: bridge
    external: false

volumes:
  # Application data
  mcp_logging_data:
    driver: local
  mcp_logging_config:
    driver: local
  mcp_logging_recovery:
    driver: local
  mcp_logging_audit:
    driver: local

  # Monitoring stack
  loki_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local